{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import openai \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import json\n",
    "\n",
    "dotenv_path = os.path.join('..', '.env')\n",
    "load_dotenv(dotenv_path)\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tutorials of using langchain for extraction etc.\n",
    "\n",
    "https://learn.deeplearning.ai/courses/functions-tools-agents-langchain/lesson/5/tagging-and-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the \"OK\" sign break up with the thumbs up? \\n\\nBecause it found someone more \"a-peeling\"!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me a short joke about {topic}\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "chain.invoke({\"topic\": \"ok\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tagging\n",
    "\n",
    "* tagging function\n",
    "* Given a function description, select arguments from the input text genreate a structure output forming a function call\n",
    "* more generally - LLM can evaluate the input text and generate a structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/journel/s0/zur74/venv/gpt_rag/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.3.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"sentiment\":\"pos\",\"language\":\"en\"}', 'name': 'Tagging'}}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 105, 'total_tokens': 115}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_9b0abffe81', 'finish_reason': 'stop', 'logprobs': None}, id='run-b23d7bf4-d974-498d-a66e-b4e9ac49bd60-0', usage_metadata={'input_tokens': 105, 'output_tokens': 10, 'total_tokens': 115})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "\n",
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n",
    "    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")\n",
    "\n",
    "convert_pydantic_to_openai_function(Tagging)\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\",temperature=0.1)\n",
    "tagging_functions = [convert_pydantic_to_openai_function(Tagging)]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and then tag the text as instructed\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={\"name\": \"Tagging\"}\n",
    ")\n",
    "\n",
    "tagging_chain = prompt | model_with_functions\n",
    "tagging_chain.invoke({\"input\": \"I love langchain\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction\n",
    "\n",
    "* when given an input json schema, the LLM has been fine tuned to find and  fill in the parameters of that schema\n",
    "* can be used as general purpose extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: Optional[int] = Field(description=\"person's age\")\n",
    "\n",
    "\n",
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")\n",
    "\n",
    "# you can add more functions here\n",
    "extraction_functions = [convert_pydantic_to_openai_function(Information)]\n",
    "extraction_model = model.bind(\n",
    "                functions=extraction_functions,\n",
    "                function_call={\"name\": \"Information\"}\n",
    "                )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "extraction_chain = prompt | extraction_model\n",
    "\n",
    "extraction_chain.invoke(\n",
    "    \"Joe is 30, his mom is Martha. She is 60. Tom is 40 and his daughter is 10.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# add json parser\n",
    "extraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()\n",
    "a = extraction_chain.invoke(\n",
    "    \"Joe is 30, his mom is Martha. She is 60. Tom is 40 and his daughter is 10.\"\n",
    "    )\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding\n",
    "\n",
    "* embedding text into a series of chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "urls = [\"https://lilianweng.github.io/posts/2023-06-23-agent/\"]\n",
    "\n",
    "loader =  UnstructuredURLLoader(urls=urls)\n",
    "documents = loader.load()\n",
    "documents = documents[0]\n",
    "\n",
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a concise summary of the content.\")\n",
    "    language: str = Field(description=\"Provide the language that the content is written in.\")\n",
    "    keywords: str = Field(description=\"Provide keywords related to the content.\")\n",
    "\n",
    "overview_tagging_function = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "tagging_model = model.bind(\n",
    "    functions=overview_tagging_function,\n",
    "    function_call={\"name\":\"Overview\"}\n",
    ")\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnm-old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
